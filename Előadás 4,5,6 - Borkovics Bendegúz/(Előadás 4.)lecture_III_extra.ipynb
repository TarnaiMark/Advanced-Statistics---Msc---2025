{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0fa5d84-28f6-43f6-a2db-30715a1c25a3",
   "metadata": {},
   "source": [
    "# Statistical models\n",
    "\n",
    "<img src=figs_III/xkcd_III.png/>\n",
    "\n",
    "## Some parametric models\n",
    "\n",
    "- Normal (Gaussian) Distribution ($\\mu$, $\\sigma$) – Defined by mean and variance, often used for modeling continuous data.\n",
    "- Binomial Distribution (n, p) – Models the number of successes in n independent trials with success probability p.\n",
    "- Poisson Distribution ($\\lambda$) – Models the count of events occurring in a fixed interval with rate $\\lambda$.\n",
    "- Exponential Distribution ($\\lambda$) – Models waiting times between independent events with rate $\\lambda$.\n",
    "- Beta Distribution ($\\alpha$, $\\beta$) – A flexible distribution for probabilities, parameterized by $\\alpha$ and $\\beta$.\n",
    "- Gamma Distribution – A generalization of the exponential distribution, often used for waiting times and reliability analysis.\n",
    "- Log-Normal Distribution – Models data where the logarithm follows a normal distribution.\n",
    "- Weibull Distribution – Used in survival analysis and reliability engineering, parameterized by shape and scale.\n",
    "- Linear Regression – Assumes a linear relationship between input variables and output with normally distributed errors.\n",
    "- Logistic Regression – Models binary outcomes using a sigmoid function to estimate probabilities.\n",
    "\n",
    "\n",
    "\n",
    "## Some non-parametric models\n",
    "\n",
    "- Kernel Density Estimation (KDE) – Estimates a probability density function using a smoothing kernel (e.g., Gaussian).\n",
    "- Histogram Density Estimation – Approximates a distribution by counting data points in fixed-width bins.\n",
    "- K-Nearest Neighbors (KNN) – Classifies a point based on the majority label of its kk nearest neighbors.\n",
    "- Decision Trees – Splits data into hierarchical regions based on feature values for classification or regression.\n",
    "- Random Forests – An ensemble of decision trees that improves accuracy and reduces overfitting.\n",
    "- Support Vector Machines (SVM) with Kernel Trick – Maps data into a higher-dimensional space using kernels for non-linear classification.\n",
    "- Locally Weighted Regression – Fits local regressions to smooth data without assuming a global functional form.\n",
    "- Spline Regression – Uses piecewise polynomials to fit flexible curves to data.\n",
    "- Empirical Cumulative Distribution Function (ECDF) – Estimates the cumulative distribution directly from observed data.\n",
    "- Bootstrap Resampling – Estimates properties (e.g., confidence intervals) by repeatedly sampling with replacement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910dff61-f212-46b0-9fec-6f0dadd5b99b",
   "metadata": {},
   "source": [
    "# Regression, prediction, classification\n",
    "\n",
    "## Regression: Predicting House Prices\n",
    "The goal is to predict the price of a house based on features like size, number of bedrooms, and location.\\\n",
    "Linear regression model:\n",
    "$$Price = \\beta_0+\\beta_1(Size)+\\beta_2(bedrooms)+\\epsilon$$\\\n",
    "The result is a continuous value (e.g., $250,000 for a house).\n",
    "\n",
    "## Prediction: Forecasting Temperature\n",
    "The aim here is to predict tomorrow’s temperature based on historical weather data.\\\n",
    "We solve this by utilizing time-series forecasting using ARIMA (Autoregressive integrated moving average) or a neural network (LSTM).\\\n",
    "We get a continuous value (e.g., \"Tomorrow’s temperature will be 75°F\").\n",
    "\n",
    "## Classification: Spam Detection\n",
    "We mean to classify emails as \"Spam\" or \"Not Spam\" based on content and metadata.\\\n",
    "$$X=\\{\\text{content, metadata}\\},\\quad Y=\\{\\text{label}\\}$$\n",
    "Some models we can use: Logistic regression, decision tree, or neural network.\\\n",
    "We obtain a binary label (e.g., \"Spam\" or \"Not Spam\").\n",
    "\n",
    "- Continuation: Data mining and machine learning course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d83ca1-05d3-4380-a56e-6165c8098f6f",
   "metadata": {},
   "source": [
    "# Point estimation with bias example\n",
    "Goal: Estimate the variance of a population based on a sample.\\\n",
    "Suppose we have a random sample $X_1,X_2,...,X_n$ from a population with true variance $\\sigma^2$.\\\n",
    "The sample variance (this is the estimator):\\\n",
    "$$S_n^2=\\frac{1}{n}\\sum^n_{i=1} \\left(X_i−\\overline{X}\\right)^2$$\n",
    "\n",
    "The bias comes into play with the expectation of $S_n^2$:\\\n",
    "$$\\mathbb{E}(S_n^2)=\\frac{n-1}{n}\\sigma^2$$\n",
    "\n",
    "This shows that $S_n^2$ underestimates $\\sigma^2$, making it a biased estimator.\\\n",
    "The unbiased sample variance corrects this bias by using:\\\n",
    "$$S_n^2=\\frac{1}{n-1}\\sum^n_{i=1} \\left(X_i−\\overline{X}\\right)^2$$\n",
    "which ensures $$\\mathbb{E}(S_n^2)=\\sigma^2.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0760aff-9b27-484a-844c-b6f1e71ed9b0",
   "metadata": {},
   "source": [
    "# Mean Squared Error calculation\n",
    "The task: We want to estimate the mean of a population using a biased estimator. We compare it to an unbiased estimator and compute the Mean Squared Error (MSE).\n",
    "1. Calculating the true population mean:\\\n",
    "    The true population values are:\\\n",
    "    $$X=\\{3,5,7,9,11\\}$$\\\n",
    "    The true mean is:\\\n",
    "    $$\\mu=\\frac{3+5+7+9+11}{5}=\\frac{35}{5}=7$$\n",
    "2. Calculating the biased amd unbiased estimators:\\\n",
    "    Unbiased estimator ($\\hat{\\mu}_U$): The sample mean using all $n$ observations. This is the same as the true mean.\\\n",
    "    Biased estimator ($\\hat{\\mu}_B$): Instead of using all data points, let's define our estimator as the mean of only the first four values:\\\n",
    "    $$\\hat{\\mu}_B=\\frac{3+5+7+9}{4}=\\frac{24}{4}​=6$$\\\n",
    "    The bias is therefore (if we always choose the first four values):\\\n",
    "    $$Bias(\\hat{\\mu}_B)=\\mathbb{E}[\\hat{\\mu}_B]−\\mu=6−7=−1.$$\n",
    "3. Computing the Mean Squared Error (MSE):\\\n",
    "    $$MSE\\left(\\hat{\\theta}\\right)=\\mathbb{E}\\left[\\left(\\hat{\\theta}−\\theta\\right)^2\\right]$$\\\n",
    "    Since our biased estimator always gives 6, the squared error is:\\\n",
    "    $$\\left(\\hat{\\theta}−\\theta\\right)^2 = (6−7)^2=(−1)^2=1$$\\\n",
    "    Since this estimator does not change across samples (always choosing the first four values), the expected squared error is also 1, so:\n",
    "    $$MSE(\\hat{\\mu}_B)=1$$\\\n",
    "    If we used the unbiased estimator ($\\hat{\\mu}_U=7$), we would get:\\\n",
    "    $$MSE(\\hat{\\mu}_U)=\\mathbb{E}\\left[(7-7)^2\\right]=0$$\\\n",
    "    showing that the unbiased estimator performs better, since the biased one leads to a higher MSE.\n",
    "\n",
    "\n",
    "\n",
    "- Helps reduce the overall errors in estimation by balancing bias and variance.\n",
    "- Lower MSE means our estimator is closer to the true value on average.\n",
    "- It penalizes large errors more (squared nature), ensuring more consistent estimates.\n",
    "- By minimizing MSE, we improve accuracy and reliability of our statistical model or estimator.\n",
    "- Expanding the concept: loss function optimization in machine learning tasks.\n",
    "\n",
    "<img src=\"figs_III/lossfunc.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2956218b-7f94-4741-bcf3-8b53e5095ef3",
   "metadata": {},
   "source": [
    "# Sample mean as an asymptotically normal estimator\n",
    "\n",
    "Let $X_1,X_2,…,X_n$ be a random sample from a population with unknown mean ($\\mu$) and finite variance ($\\sigma^2$) and we want to estimate the mean.\\\n",
    "$$\\hat{\\mu}_n=\\frac{1}{n}\\sum^n_{i=1}X_i$$\n",
    "1. Checking for asymptotic normality:\\\n",
    "    According to the Central Limit Theorem (CLT), as $n\\rightarrow\\infty$, the distribution of $\\hat{\\mu}_n$ approaches a normal distribution:\\\n",
    "    $$\\sqrt{n}\\left(\\hat{\\mu}_n-\\mu\\right)\\xrightarrow{d}\\mathcal{N}(0,\\sigma^2)$$\\\n",
    "    This means that, for large $n$, the sample mean $\\hat{\\mu}_n$ follows an approximate normal distribution, even if the original data is not normally distributed.\n",
    "2. We have a population with $\\mu=50$ (true mean) and $\\sigma^2=100$ (population variance). We take a random sample of size $n=100$ and calculate the sample mean $\\hat{\\mu}_n$.\\\n",
    "    The variance of the sample mean is:\\\n",
    "    $$Var(\\hat{\\mu}_n)=\\frac{\\sigma^2}{n}$$\\\n",
    "    By the CLT, for large $n$:\\\n",
    "    $$\\hat{\\mu_{100}}\\approx\\mathcal{N}\\left(50,\\frac{100}{100}\\right)=\\mathcal{N}(50,1)$$\\\n",
    "    So, if we take repeated samples and compute sample means, they will be approximately normal with mean 50 and variance 1.\n",
    "    \n",
    "- This property is useful for constructing confidence intervals and hypothesis tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396163c8-5ca3-40d9-a3dd-7af4f9edab48",
   "metadata": {},
   "source": [
    "# Confidence interval\n",
    "\n",
    "## Simple calculation: small dataset\n",
    "Task: We measure the heights (in cm) of 5 people: $X=\\{160,165,170,175,180\\}$. We want to estimate the population mean height with a $95\\%$ confidence interval.\n",
    "1. Computing the sample mean:\\\n",
    "    $$\\overline{X}=\\frac{160+165+170+175+180}{5}=\\frac{850}{5}=170$$\n",
    "2. Computing the sample standard deviation:\\\n",
    "    $$\\sigma=\\sqrt{\\frac{(160−170)^2+(165−170)^2+(170−170)^2+(175−170)^2+(180−170)^2}{5−1}}=\\sqrt{\\frac{250}{4}}\\approx 7.91$$\n",
    "3. Computing the standard error:\\\n",
    "    $$se\\left(\\overline{X}\\right)=\\sqrt{Var\\left(\\overline{X}\\right)}=\\sqrt{\\frac{\\sigma^2}{n}}=\\sqrt{\\frac{7.91^2}{5}}\\approx 3.54$$\n",
    "4. Find the $t$-critical value:\\\n",
    "    A $t$-test is generally preferable when dealing with small datasets ($n<30$) and when we do not know the population standard deviation.\\\n",
    "    This is a two-tailed test. For a $95\\%$ confidence level with 4 degrees of freedom ($n-1=5-1=4$), the $t$-value (from a $t$-table) is 2.776.\n",
    "5. Computing the confidence interval:\\\n",
    "    $$\\overline{X}\\pm (t\\cdot se)=170\\pm(2.776\\cdot3.54)=170\\pm9.83=(160.17,179.83)$$\\\n",
    "    With $95\\%$ confidence, the population mean height is between 160.17 cm and 179.83 cm.\n",
    "    \n",
    "## Normal-based confidence interval calculation: large dataset\n",
    "Task: We survey 100 students and find: sample mean test score: $\\overline{X}=75$, known population standard deviation: $\\sigma=10$, confidence level: $95\\%$.\n",
    "1. Computing the standard error (because of the known $\\sigma$, we do not need to use the estimate of $se$):\\\n",
    "    $$se=\\sqrt{\\frac{\\sigma^2}{n}}=\\sqrt{\\frac{100}{100}}=1$$\n",
    "2. Find the $z$-critical value:\\\n",
    "    A $z$-test is generally preferable when dealing with larger datasets ($n\\geq30$) and when we do know the population standard deviation.\\\n",
    "    For $95\\%$ confidence, the $z$-value (from a $z$-table) is 1.96.\n",
    "3. Computing the confidence interval:\n",
    "    $$\\overline{X}\\pm(z\\cdot se)=75\\pm(1.96\\cdot1)=75\\pm1.96=(73.04,76.96)$$\\\n",
    "    With 95% confidence, the population mean test score is between 73.04 and 76.96."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "878a8298-1170-4def-9db6-d8afa667f9c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-value: 2.7764451051977987\n",
      "Z-critical value: 1.959963984540054\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "#2-tailed t-test (for 1-tailed: q= 1-0.05)\n",
    "print(f\"t-value: {stats.t.ppf(q=1-(0.05)/2, df = 4)}\")\n",
    "\n",
    "z_value = stats.norm.ppf(1-(0.05)/2)\n",
    "print(f\"Z-critical value: {z_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbc8b2a-ed96-430c-8adb-3270e221aa22",
   "metadata": {},
   "source": [
    "## Some confidence interval homework\n",
    "\n",
    "- $Z$-test confidence intervals (Use $Z$-distribution, assume known population variance)\n",
    "    1. A sample of $n=50$ students has an average SAT score of 1050 with a known population standard deviation of 100. Compute a 95% confidence interval for the population mean SAT score.\n",
    "    2. A factory produces bolts with an average length of 5.2 cm. A quality control sample of $n=40$ bolts has a mean length of 5.25 cm, and the population standard deviation is known to be 0.1 cm. Find the 99% confidence interval for the true mean length of all bolts.\n",
    "    3. A researcher surveys $n=200$ customers and finds that 65% of them prefer online shopping. Compute a 90% confidence interval for the true proportion of customers who prefer online shopping.\n",
    "\n",
    "- $t$-test confidence intervals (Use $t$-distribution, assume unknown population variance)\n",
    "    1. A small sample of $n=10$ patients has an average systolic blood pressure of 120 mmHg with a sample standard deviation of 15 mmHg. Find the 95% confidence interval for the population mean blood pressure.\n",
    "    2. A group of $n=15$ students took a math test, and their average score was 78 with a sample standard deviation of 10. Compute a 99% confidence interval for the true average test score.\n",
    "    3. A nutritionist collects data from $n=8$ people on their daily calorie intake. The sample mean is 2200 calories, and the sample standard deviation is 250 calories. Find the 90% confidence interval for the average calorie intake in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e98c094-bd18-4a6d-859f-cd25d4946684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa44b8a-7167-4139-b488-6b1f3d88979b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863a8f47-734b-4c64-9175-cd1ed1e0c474",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
